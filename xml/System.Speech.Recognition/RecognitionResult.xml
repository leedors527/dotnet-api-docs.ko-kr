<Type Name="RecognitionResult" FullName="System.Speech.Recognition.RecognitionResult">
  <Metadata><Meta Name="ms.openlocfilehash" Value="d8c11e0953e9268493e690134180ca5d564cb65e" /><Meta Name="ms.sourcegitcommit" Value="756d085f27705e86604f1bba5f2086ee23761acf" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="ko-KR" /><Meta Name="ms.lasthandoff" Value="01/30/2019" /><Meta Name="ms.locfileid" Value="55363479" /></Metadata><TypeSignature Language="C#" Value="public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable sealed beforefieldinit RecognitionResult extends System.Speech.Recognition.RecognizedPhrase implements class System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognitionResult" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class RecognitionResult&#xA;Inherits RecognizedPhrase&#xA;Implements ISerializable" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognitionResult sealed : System::Speech::Recognition::RecognizedPhrase, System::Runtime::Serialization::ISerializable" />
  <TypeSignature Language="F#" Value="type RecognitionResult = class&#xA;    inherit RecognizedPhrase&#xA;    interface ISerializable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognizedPhrase</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.Runtime.Serialization.ISerializable</InterfaceName>
    </Interface>
  </Interfaces>
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")</AttributeName>
    </Attribute>
    <Attribute>
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> 또는 <see cref="T:System.Speech.Recognition.SpeechRecognizer" />의 인스턴스에 의해 인식된 입력에 대한 자세한 정보를 포함합니다.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 클래스에서 파생 됩니다 <xref:System.Speech.Recognition.RecognizedPhrase> 하 고 다음을 포함 한 음성 인식에 대 한 자세한 정보를 제공 합니다.  
  
-   합니다 <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> 속성 참조는 <xref:System.Speech.Recognition.Grammar> 인식기 음성을 식별 하는 데 사용 합니다.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> 속성 구에 대 한 정규화 된 텍스트를 포함 합니다. 텍스트 정규화에 대 한 자세한 내용은 참조 하세요. <xref:System.Speech.Recognition.ReplacementText>합니다.  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> 결과에 포함 된 의미 체계 정보를 참조 하는 속성입니다. 의미 체계 정보에는 키 이름 및 연결 된 의미 체계 데이터의 사전입니다.  
  
-   합니다 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> 속성의 컬렉션을 포함 <xref:System.Speech.Recognition.RecognizedPhrase> 오디오 입력의 다른 후보 해석을 나타내는 개체입니다. 자세한 내용은 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>를 참조하세요.  
  
-   합니다 <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> 속성의 정렬된 된 컬렉션이 포함 <xref:System.Speech.Recognition.RecognizedWordUnit> 각각 나타내는 개체를 입력의 단어를 인식 합니다. 각 <xref:System.Speech.Recognition.RecognizedWordUnit> 표시 형식, 어휘 형식 및 해당 단어의 발음 정보를 포함 합니다.  
  
 특정 멤버를 <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, 및 <xref:System.Speech.Recognition.Grammar> 클래스를 생성할 수는 <xref:System.Speech.Recognition.RecognitionResult>합니다. 자세한 내용은 다음 메서드 및 이벤트를 참조 하세요.  
  
-   메서드 및 이벤트는 <xref:System.Speech.Recognition.SpeechRecognitionEngine> 클래스:  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>  
  
-   메서드 및 이벤트는 <xref:System.Speech.Recognition.SpeechRecognizer> 클래스:  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>  
  
-   합니다 <xref:System.Speech.Recognition.Grammar.SpeechRecognized> 의 이벤트는 <xref:System.Speech.Recognition.Grammar> 클래스입니다.  
  
 인식 이벤트에 대 한 자세한 내용은 참조 하세요. [음성 인식 이벤트를 사용 하 여](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)입니다.  
  
   
  
## Examples  
 다음 예제에 대 한 처리기를 보여 줍니다.는 `SpeechRecognized` 의 이벤트를 <xref:System.Speech.Recognition.SpeechRecognitionEngine> 또는 <xref:System.Speech.Recognition.SpeechRecognizer> 개체와 연결된 된 정보 중 일부 <xref:System.Speech.Recognition.RecognitionResult>합니다.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
  </Docs>
  <Members>
    <Member MemberName="Alternates">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Alternates { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Alternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Alternates As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Alternates { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Alternates : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;" Usage="System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>음성 인식기 입력이 가능한 일치 항목의 컬렉션을 가져옵니다.</summary>
        <value>인식 대체의 읽기 전용 컬렉션입니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> 의 값으로 정렬 됩니다 해당 <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> 속성입니다. 지정 된 구 신뢰성 값 라는 문구는 입력과 일치 하는 확률을 나타냅니다. 가장 높은 신뢰성 값을 사용 하 여 구는 대부분의 입력과 일치 하는 구입니다.  
  
 각 <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> 개별적으로 및 다른 신뢰도 값에 대 한 참조 없이 값을 계산할 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>합니다. 속성 하는 <xref:System.Speech.Recognition.RecognitionResult> 에서 상속 <xref:System.Speech.Recognition.RecognizedPhrase> 신뢰도 점수가 가장 높은 라는 문구에 대 한 자세한 정보를 제공 합니다.  
  
 에 대 한 한 가지 용도 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> 컬렉션은 자동화 된 오류 수정에 대 한 합니다. 예를 들어 디렉터리 대화 상자를 디자인할 때 애플리케이션 묻는 메시지가 애플리케이션에서와 같이 인식 이벤트에서 올바른 정보가 입력 되었는지 "가 필요 하다 'Anna'?"를 확인 하려면 사용자가 말하는 "no" 인 경우 애플리케이션에서 충분히 높은 있던 모든 대체 하는 방법에 대 한 사용자를 쿼리할 수 있습니다 <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> 점수입니다.  
  
 음성 인식 및 인식 대체 항목을 사용 하는 방법에 대 한 자세한 내용은 참조 하세요. [음성 인식](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361633(v=office.14)) 하 고 [음성 인식 이벤트를 사용 하 여](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)입니다.  
  
   
  
## Examples  
 다음 예제에 대 한 처리기를 `SpeechRecognized` 이벤트와 연결된 된 정보 중 일부 <xref:System.Speech.Recognition.RecognitionResult>합니다.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
      </Docs>
    </Member>
    <Member MemberName="Audio">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio Audio { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizedAudio Audio" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Audio As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizedAudio ^ Audio { System::Speech::Recognition::RecognizedAudio ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Audio : System.Speech.Recognition.RecognizedAudio" Usage="System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식 결과와 연결된 오디오를 가져옵니다.</summary>
        <value>인식기가 <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> 또는 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 인스턴스의 <see langword="null" /> 또는 <see langword="EmulateRecognize" /> 메서드 호출로 인한 결과를 생성하는 경우, 인식 결과와 연결된 오디오 또는 <see langword="EmulateRecognizeAsync" /></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 단어 인식 결과에서 특정 범위와 연결 된 오디오 섹션을 사용 합니다 <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> 메서드.  
  
   
  
## Examples  
 다음 예제에 대 한 처리기를 **SpeechRecognized** 이벤트와 연결된 된 정보 중 일부 <xref:System.Speech.Recognition.RecognitionResult>합니다.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
      Console.WriteLine("Audio for result:");  
      Console.WriteLine("  Start time: "+ e.Result.Audio.StartTime);  
      Console.WriteLine("  Duration: " + e.Result.Audio.Duration);  
      Console.WriteLine("  Format: " + e.Result.Audio.Format.EncodingFormat);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      </Docs>
    </Member>
    <Member MemberName="GetAudioForWordRange">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognizedAudio GetAudioForWordRange(class System.Speech.Recognition.RecognizedWordUnit firstWord, class System.Speech.Recognition.RecognizedWordUnit lastWord) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      <MemberSignature Language="VB.NET" Value="Public Function GetAudioForWordRange (firstWord As RecognizedWordUnit, lastWord As RecognizedWordUnit) As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognizedAudio ^ GetAudioForWordRange(System::Speech::Recognition::RecognizedWordUnit ^ firstWord, System::Speech::Recognition::RecognizedWordUnit ^ lastWord);" />
      <MemberSignature Language="F#" Value="member this.GetAudioForWordRange : System.Speech.Recognition.RecognizedWordUnit * System.Speech.Recognition.RecognizedWordUnit -&gt; System.Speech.Recognition.RecognizedAudio" Usage="recognitionResult.GetAudioForWordRange (firstWord, lastWord)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="firstWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
        <Parameter Name="lastWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
      </Parameters>
      <Docs>
        <param name="firstWord">범위 내에서 첫 번째 단어입니다.</param>
        <param name="lastWord">범위 내에서 마지막 단어입니다.</param>
        <summary>인식 결과에서 특정 단어 범위와 연결된 오디오 섹션을 가져옵니다.</summary>
        <returns>단어 범위와 관련된 오디오 섹션입니다.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 전체 오디오를 인식 결과와 연결을 사용 합니다 <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> 속성입니다.  
  
   
  
## Examples  
 다음 예제에서는 이름 입력을 허용 하는 문법에 대해서 만들고에 대 한 처리기를 연결 합니다 `SpeechRecognized` 이벤트입니다. 문법 구의 name 요소에 대 한 와일드 카드를 사용 합니다. 이벤트 처리기는 와일드 카드에서 오디오를 사용 하 여 만들고 인사말 프롬프트를 재생 합니다.  
  
```csharp  
  
private Grammar CreateNameInputGrammar()  
{  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey nameKey =  
    new SemanticResultKey("Name", wildcardBuilder);  
  
  GrammarBuilder nameBuilder =  
    new GrammarBuilder("My name is");  
  nameBuilder.Append(nameKey);  
  
  Grammar nameGrammar = new Grammar(nameBuilder);  
  nameGrammar.Name = "Name input";  
  
  nameGrammar.SpeechRecognized +=  
    new EventHandler<SpeechRecognizedEventArgs>(  
      NameInputHandler);  
  
  return nameGrammar;  
}  
  
// Handle the SpeechRecognized event for the name grammar.  
private void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  SemanticValue semantics = e.Result.Semantics;  
  
  if (semantics.ContainsKey("Name"))  
  {  
    RecognizedAudio nameAudio =  
      result.GetAudioForWordRange(  
        result.Words[3], result.Words[result.Words.Count - 1]);  
  
    // Save the audio. Create a directory and file as necessary.  
    FileInfo fi = new FileInfo(@"C:\temp\temp.wav");  
    if (!fi.Directory.Exists)  
    {  
      fi.Directory.Create();  
    }  
    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  
    nameAudio.WriteToWaveStream(stream);  
    stream.Close();  
  
    // Greet the person using the saved audio.  
    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("Hello");  
    builder.AppendAudio(fi.FullName);  
    synthesizer.Speak(builder);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.NullReferenceException"><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 또는 <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> 개체의 <see langword="EmulateRecognize" /> 또는 <see langword="EmulateRecognizeAsync" /> 메서드에 대한 호출 결과 생성된 인식기</exception>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Audio" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="System.Runtime.Serialization.ISerializable.GetObjectData">
      <MemberSignature Language="C#" Value="void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);" />
      <MemberSignature Language="ILAsm" Value=".method hidebysig newslot virtual instance void System.Runtime.Serialization.ISerializable.GetObjectData(class System.Runtime.Serialization.SerializationInfo info, valuetype System.Runtime.Serialization.StreamingContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)" />
      <MemberSignature Language="VB.NET" Value="Sub GetObjectData (info As SerializationInfo, context As StreamingContext) Implements ISerializable.GetObjectData" />
      <MemberSignature Language="C++ CLI" Value=" virtual void System.Runtime.Serialization.ISerializable.GetObjectData(System::Runtime::Serialization::SerializationInfo ^ info, System::Runtime::Serialization::StreamingContext context) = System::Runtime::Serialization::ISerializable::GetObjectData;" />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.Runtime.Serialization.ISerializable.GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="info" Type="System.Runtime.Serialization.SerializationInfo" />
        <Parameter Name="context" Type="System.Runtime.Serialization.StreamingContext" />
      </Parameters>
      <Docs>
        <param name="info">데이터로 채울 개체입니다.</param>
        <param name="context">serialization의 대상입니다.</param>
        <summary>대상 개체를 serialize하는 데 필요한 데이터로 <see cref="T:System.Runtime.Serialization.SerializationInfo" /> 인스턴스를 채웁니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 멤버는 명시적 인터페이스 멤버 구현이며, <xref:System.Speech.Recognition.RecognitionResult> 인스턴스가 <xref:System.Runtime.Serialization.ISerializable> 인터페이스로 캐스팅된 경우에만 사용할 수 있습니다.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Runtime.Serialization.ISerializable" />
        <altmember cref="T:System.Runtime.Serialization.SerializationInfo" />
        <altmember cref="T:System.Runtime.Serialization.StreamingContext" />
      </Docs>
    </Member>
  </Members>
</Type>