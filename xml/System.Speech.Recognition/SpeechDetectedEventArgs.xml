<Type Name="SpeechDetectedEventArgs" FullName="System.Speech.Recognition.SpeechDetectedEventArgs">
  <Metadata><Meta Name="ms.openlocfilehash" Value="032a655b78a279551e6e9fc3ef3d4b1a8275f963" /><Meta Name="ms.sourcegitcommit" Value="0e1f030650a307c745ee84ed547ef858acaea587" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="ko-KR" /><Meta Name="ms.lasthandoff" Value="11/29/2018" /><Meta Name="ms.locfileid" Value="52594718" /></Metadata><TypeSignature Language="C#" Value="public class SpeechDetectedEventArgs : EventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechDetectedEventArgs extends System.EventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechDetectedEventArgs&#xA;Inherits EventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechDetectedEventArgs : EventArgs" />
  <TypeSignature Language="F#" Value="type SpeechDetectedEventArgs = class&#xA;    inherit EventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.EventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary><see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" /> 또는 <see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" /> 이벤트의 데이터를 반환합니다.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 A `SpeechDetected` 이벤트를 발생 합니다 <xref:System.Speech.Recognition.SpeechRecognizer> 및 <xref:System.Speech.Recognition.SpeechRecognitionEngine> 클래스입니다.  
  
 **SpeechDetected** 인식 엔진으로 실제 음성 오디오 입력을 식별할 수 있습니다 하는 경우 이벤트가 생성 됩니다.  
  
 <xref:System.Speech.Recognition.SpeechDetectedEventArgs>은 <xref:System.EventArgs>로부터 파생됩니다.  
  
   
  
## Examples  
 아래 예제에 대 한 처리기를 만듭니다 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType> 또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType> 이벤트입니다. 처리기를 검색 하 고 오디오 위치를 포함 하 여 상태 정보를 표시 하는 음성 때마다 디스플레이 초기화 합니다.  
  
```  
_recognizer.SpeechDetected +=  
  delegate(object sender, SpeechDetectedEventArgs eventArgs)   
  {  
  
    // Clear previous recognition information.  
    _audioDeviceStatusLabel.Enabled = true;  
    _audioDeviceStatusLabel.Visible = true;  
    Utils.DisplayAudioInputFormat(_audioStateLabel, _recognizer);  
    Utils.DisplayRecognizerState(_recognizerStateLabel, _recognizer.State);  
    Utils.DisplaySpeechDetected(_speechDetectedLabel, eventArgs.AudioPosition);  
  };  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
  </Docs>
  <Members>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>음성을 감지한 오디오 스트림에서 위치를 가져옵니다.</summary>
        <value>검색된 된 구 인식 엔진의 음성 버퍼 내에서 위치를 반환합니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 아래 예제에 대 한 처리기를 만듭니다 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType> 또는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType> 이벤트입니다. 처리기를 검색 하 고 오디오 위치를 포함 하 여 상태 정보를 표시 하는 각 시간 음성 디스플레이 초기화 합니다.  
  
```  
_recognizer.SpeechDetected +=  
  delegate(object sender, SpeechDetectedEventArgs eventArgs)   
  {  
  
    // Clear previous recognition information.  
    _audioDeviceStatusLabel.Enabled = true;  
    _audioDeviceStatusLabel.Visible = true;  
    Utils.DisplayAudioInputFormat(_audioStateLabel, _recognizer);  
    Utils.DisplayRecognizerState(_recognizerStateLabel, _recognizer.State);  
    Utils.DisplaySpeechDetected(_speechDetectedLabel, eventArgs.AudioPosition);  
  };  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
      </Docs>
    </Member>
  </Members>
</Type>