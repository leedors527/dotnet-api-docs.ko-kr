<Type Name="SpeechRecognizer" FullName="System.Speech.Recognition.SpeechRecognizer">
  <Metadata><Meta Name="ms.openlocfilehash" Value="7f19e98d364cd16bffbf58714877f22e676a4052" /><Meta Name="ms.sourcegitcommit" Value="0e1f030650a307c745ee84ed547ef858acaea587" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="ko-KR" /><Meta Name="ms.lasthandoff" Value="11/29/2018" /><Meta Name="ms.locfileid" Value="52596031" /></Metadata><TypeSignature Language="C#" Value="public class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechRecognizer extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizer&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="F#" Value="type SpeechRecognizer = class&#xA;    interface IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary>윈도우즈 바탕화면에서 사용할 수 있는 공유 스피치 인식 서비스에 접근한다.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Windows 음성 인식 액세스 하려면 공유 인식기를 사용 하는 애플리케이션. 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer> Windows 음성 사용자 환경에 추가할 개체입니다.  
  
 이 클래스는 다양 한 음성 인식 프로세스에 대 한 제어를 제공합니다.  
  
-   음성 인식 문법을 관리 하려면 사용 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>를 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>합니다.  
  
-   구독할에 정보를 가져오려면 현재 음성에 대 한 인식 작업을 <xref:System.Speech.Recognition.SpeechRecognizer>의 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>를 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트입니다.  
  
-   보거나 인식기에서 반환 하는 대체 결과 수를 수정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> 속성입니다. 인식기에서 인식 결과 반환 합니다.는 <xref:System.Speech.Recognition.RecognitionResult> 개체입니다.  
  
-   를 액세스 하거나 공유 된 인식기의 상태를 모니터링 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>를 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> 속성 및 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> 이벤트입니다.  
  
-   인식기에 대 한 변경 내용을 동기화에 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 메서드. 공유 인식기가 둘 이상의 스레드를 사용 하 여 작업을 수행할 수 있습니다.  
  
-   공유 인식기에 대 한 입력을 에뮬레이션 하기 위해 사용 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> 고 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 메서드.  
  
 Windows 음성 인식의 구성을 사용 하 여 관리 되는 **음성 속성** 대화 상자에는 **제어판**합니다. 이 인터페이스는 기본 데스크톱 음성 인식 엔진 및 언어, 오디오 입력된 디바이스 및 음성 인식의 절전 모드 동작 선택에 사용 됩니다. (예를 들어 경우 음성 인식을 사용 불가능 하거나 입력된 언어가 변경 된) 애플리케이션이 실행 되는 동안 Windows 음성 인식의 구성을 변경 하는 경우, 변경 내용이 모두 적용 <xref:System.Speech.Recognition.SpeechRecognizer> 개체입니다.  
  
 Windows 음성 인식의 관계는 in process 음성 인식기를 만들려면 사용 합니다 <xref:System.Speech.Recognition.SpeechRecognitionEngine> 클래스입니다.  
  
> [!NOTE]
>  항상 호출 <xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A> 음성 인식기에 대 한 마지막 참조를 해제 하기 전에 합니다. 가비지 수집기는 인식기 개체를 호출할 때까지 사용 중인 리소스를 해제 되지 것입니다이 고, 그렇지 `Finalize` 메서드.  
  
   
  
## Examples  
 다음 예제는 콘솔 애플리케이션을 음성 인식 문법을 로드 및 비동기 에뮬레이트된 입력, 연결 된 인식 결과 및 음성 인식기에 의해 발생 하는 연결 된 이벤트를 보여 줍니다.  Windows 음성 인식을 실행 하지 않는 경우 다음이 애플리케이션을 시작 Windows 음성 인식 됩니다도 시작 됩니다. Windows 음성 인식이 경우 합니다 **중지** 상태 이면 다음 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 항상 null을 반환 합니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="T:System.Speech.Recognition.Grammar" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognizer();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 클래스의 새 인스턴스를 초기화합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 각 <xref:System.Speech.Recognition.SpeechRecognizer> 개체는 음성 인식 문법의 개별 집합을 유지 합니다.  
  
   
  
## Examples  
 다음 예제는 콘솔 애플리케이션을 음성 인식 문법을 로드 및 비동기 에뮬레이트된 입력, 연결 된 인식 결과 및 음성 인식기에 의해 발생 하는 연결 된 이벤트를 보여 줍니다. Windows 음성 인식을 실행 하지 않는 경우 다음이 애플리케이션을 시작 Windows 음성 인식 됩니다도 시작 됩니다. Windows 음성 인식이 경우 합니다 **중지** 상태 이면 다음 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 항상 null을 반환 합니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
    <Member MemberName="AudioFormat">
      <MemberSignature Language="C#" Value="public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioFormat As SpeechAudioFormatInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::AudioFormat::SpeechAudioFormatInfo ^ AudioFormat { System::Speech::AudioFormat::SpeechAudioFormatInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioFormat : System.Speech.AudioFormat.SpeechAudioFormatInfo" Usage="System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.AudioFormat.SpeechAudioFormatInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>음성 인식기가 수신하는 오디오의 형식을 가져옵니다.</summary>
        <value>인식기에 대한 입력을 구성하지 않은 경우 음성 인식기에 대한 오디오 입력 또는 <see langword="null" /></value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioLevel">
      <MemberSignature Language="C#" Value="public int AudioLevel { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 AudioLevel" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioLevel As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int AudioLevel { int get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioLevel : int" Usage="System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>음성 인식기가 수신하는 오디오의 수준을 가져옵니다.</summary>
        <value>음성 인식기에 대한 오디오 입력 수준(0에서 100까지)입니다.</value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      </Docs>
    </Member>
    <Member MemberName="AudioLevelUpdated">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioLevelUpdated As EventHandler(Of AudioLevelUpdatedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioLevelUpdatedEventArgs ^&gt; ^ AudioLevelUpdated;" />
      <MemberSignature Language="F#" Value="member this.AudioLevelUpdated : EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " Usage="member this.AudioLevelUpdated : System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>오디오 입력 수준 공유 인식기를 보고 하면 발생 합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기에는 초당 여러 번이이 이벤트가 발생합니다. 애플리케이션이 실행 되는 컴퓨터의 이벤트는 발생 빈도 따라 달라 집니다.  
  
 오디오 수준에서 이벤트의 시간을 사용 합니다 <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> 속성은 연결 된 <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>합니다. 현재 오디오 수준의 인식기에 대 한 입력을 사용 하면 인식기의 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> 속성입니다.  
  
 에 대 한 대리자를 만들 때는 `AudioLevelUpdated` 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제에 대 한 처리기를 추가 합니다 `AudioLevelUpdated` 이벤트를를 <xref:System.Speech.Recognition.SpeechRecognizer> 개체입니다. 처리기는 콘솔에 새 오디오 수준을 출력합니다.  
  
```csharp  
private SpeechRecognizer recognizer;  
  
// Initialize the SpeechRecognizer object.   
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add an event handler for the AudioLevelUpdated event.  
  recognizer.AudioLevelUpdated +=   
    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  
  
  // Add other initialization code here.  
  
}  
  
// Write the audio level to the console when the AudioLevelUpdated event is raised.  
void recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  
{  
  Console.WriteLine("The audio level is now: {0}.", e.AudioLevel);  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioLevelUpdatedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      </Docs>
    </Member>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>음성 인식기에 입력을 공급하는 디바이스가 생성하고 있는 오디오 스트림에서 현재 위치를 가져옵니다.</summary>
        <value>입력을 받은 음성 인식기의 오디오 입력 스트림의 현재 위치입니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 데스크톱 음성 인식 실행 되는 동안 공유 인식기 입력을 받습니다.  
  
 `AudioPosition` 속성이 생성 된 해당 오디오 스트림에서 입력된 장치의 위치를 참조 합니다. 반면,는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 속성 처리 오디오 입력 인식기의 위치를 참조 합니다. 이러한 위치는 다를 수 있습니다.  예를 들어 인식기에서 받은 입력 하지 있는 it에 아직 경우 인식 결과 다음 값을 생성 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 속성의 값 보다 작으면는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 속성.  
  
   
  
## Examples  
 다음 예제에서는 공유 음성 인식기는 음성 입력와 일치 하도록 받아쓰기 문법을 사용 합니다. 에 대 한 처리기를 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> 가 콘솔에 쓰는 이벤트를 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>를 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> 음성 인식기에서 입력 음성을 감지 하는 경우.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add handlers for events.  
      recognizer.LoadGrammarCompleted +=   
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
      recognizer.SpeechRecognized +=   
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
      recognizer.SpeechDetected +=   
        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
  
      // Create a dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load the grammar object to the recognizer.  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Gather information about detected speech and write it to the console.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Speech detected:");  
      Console.WriteLine("  Audio level: " + recognizer.AudioLevel);  
      Console.WriteLine("  Audio position: " + recognizer.AudioPosition);  
      Console.WriteLine("  Recognizer audio position: " + recognizer.RecognizerAudioPosition);  
    }  
  
    // Write the text of the recognition result to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {   
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Write the name of the loaded grammar to the console.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="AudioSignalProblemOccurred">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioSignalProblemOccurred As EventHandler(Of AudioSignalProblemOccurredEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioSignalProblemOccurredEventArgs ^&gt; ^ AudioSignalProblemOccurred;" />
      <MemberSignature Language="F#" Value="member this.AudioSignalProblemOccurred : EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " Usage="member this.AudioSignalProblemOccurred : System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식기에서 오디오 신호에 문제가 발견 되 면 발생 합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 어떤 문제가 발생 했습니다.을 사용 합니다 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> 속성은 연결 된 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>합니다.  
  
 에 대 한 대리자를 만들 때는 `AudioSignalProblemOccurred` 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제에서는 정의 대 한 정보를 수집 하는 이벤트 처리기는 `AudioSignalProblemOccurred` 이벤트입니다.  
  
```  
private SpeechRecognizer recognizer;  
  
// Initialize the speech recognition engine.  
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add a handler for the AudioSignalProblemOccurred event.  
  recognizer.AudioSignalProblemOccurred +=   
    new EventHandler<AudioSignalProblemOccurredEventArgs>(  
      recognizer_AudioSignalProblemOccurred);  
}  
  
// Gather information when the AudioSignalProblemOccurred event is raised.  
void recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  
{  
  StringBuilder details = new StringBuilder();  
  
  details.AppendLine("Audio signal problem information:");  
  details.AppendFormat(  
    " Audio level:               {0}" + Environment.NewLine +  
    " Audio position:            {1}" + Environment.NewLine +  
    " Audio signal problem:      {2}" + Environment.NewLine +  
    " Recognition engine audio position: {3}" + Environment.NewLine,  
    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  
    e.recoEngineAudioPosition);  
  
  // Insert additional event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblem" />
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="AudioState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioState AudioState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioState AudioState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioState As AudioState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioState AudioState { System::Speech::Recognition::AudioState get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioState : System.Speech.Recognition.AudioState" Usage="System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>음성 인식기가 수신하는 오디오의 상태를 가져옵니다.</summary>
        <value>음성 인식기에 대한 오디오 입력 상태입니다.</value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      </Docs>
    </Member>
    <Member MemberName="AudioStateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioStateChanged As EventHandler(Of AudioStateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioStateChangedEventArgs ^&gt; ^ AudioStateChanged;" />
      <MemberSignature Language="F#" Value="member this.AudioStateChanged : EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " Usage="member this.AudioStateChanged : System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식기가 수신하는 오디오의 상태가 변경되면 발생합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 오디오 상태 이벤트의 타임을 사용 합니다 <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> 속성은 연결 된 <xref:System.Speech.Recognition.AudioStateChangedEventArgs>합니다. 인식기에 대 한 입력의 오디오 현재 상태를 가져오려면 인식기를 사용 하 여 <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> 속성입니다. 오디오의 상태에 대 한 자세한 내용은 참조는 <xref:System.Speech.Recognition.AudioState> 열거형입니다.  
  
 에 대 한 대리자를 만들 때는 `AudioStateChanged` 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제에서는 대 한 처리기를 `AudioStateChanged` 인식기를 작성 하는 이벤트의 새 <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> 콘솔에이 변경 될 때마다의 멤버를 사용 하는 <xref:System.Speech.Recognition.AudioState> 열거형.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Create and load a grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the AudioStateChanged event.  
    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("The new audio state is: " + e.AudioState);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine();  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
        Console.WriteLine();  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Done.");  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the recognizer into Listening mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        Console.WriteLine();  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
        <altmember cref="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      </Docs>
    </Member>
    <MemberGroup MemberName="Dispose">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 개체를 삭제합니다.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberSignature Language="F#" Value="abstract member Dispose : unit -&gt; unit&#xA;override this.Dispose : unit -&gt; unit" Usage="speechRecognizer.Dispose " />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 개체를 삭제합니다.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected virtual void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig newslot virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overridable Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="C++ CLI" Value="protected:&#xA; virtual void Dispose(bool disposing);" />
      <MemberSignature Language="F#" Value="abstract member Dispose : bool -&gt; unit&#xA;override this.Dispose : bool -&gt; unit" Usage="speechRecognizer.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing">관리되는 리소스와 관리되지 않는 리소스를 모두 해제하려면 <see langword="true" />로 설정하고, 관리되지 않는 리소스만 해제하려면 <see langword="false" />로 설정합니다.</param>
        <summary><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 개체를 삭제하고 세션 중에 사용되는 리소스를 해제합니다.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognize">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>동기 음성 인식을 위한 오디오 대신 텍스트를 사용하여 공유 음성 인식기 입력을 에뮬레이트합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이러한 메서드는 시스템 오디오 입력을 무시합니다. 이 기능은 테스트 하거나 애플리케이션 또는 문법 디버깅 하는 경우에 유용할 수 있습니다.  
  
> [!NOTE]
>  Windows 음성 인식이 경우 합니다 **중지** 상태를 반환 하는 이러한 메서드 `null`합니다.  
  
 공유 인식기가 발생 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트 것 처럼 인식 작업은 에뮬레이트되지 않습니다. 인식기 새 줄 및 추가 공백을 무시 하 고 리터럴 입력으로 문장 부호를 처리 합니다.  
  
> [!NOTE]
>  합니다 <xref:System.Speech.Recognition.RecognitionResult> 공유 인식기 에뮬레이트된 입력에 대 한 응답에서으로 생성 된 개체의 값이 `null` 에 대 한 해당 <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> 속성입니다.  
  
 비동기 인식의 에뮬레이션 하기 위해 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 메서드.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function EmulateRecognize (inputText As String) As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">인식 작업에 필요한 입력입니다.</param>
        <summary>동기 음성 인식용 오디오 대신 텍스트를 사용하여 공유 음성 인식기에 구 입력을 에뮬레이션합니다.</summary>
        <returns>인식 작업에 대한 인식 결과, 또는 작업이 성공하지 않았거나 Windows 음성 인식이 **중지** 상태인 경우 <see langword="null" /></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기 Vista 및 Windows 7을 사용 하 여 제공 되는 대/소문자 무시 및 문자 너비 입력된 구를 문법 규칙을 적용 합니다. 이 유형의 비교에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions> 열거형 값 <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 및 <xref:System.Globalization.CompareOptions.IgnoreWidth>합니다. 또한 인식자 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다.  
  
   
  
## Examples  
 다음 예제에서는 샘플 문법을 공유 인식기에 로드 및 인식기에 입력을 에뮬레이션 합니다. Windows 음성 인식을 실행 하지 않는 경우 다음이 애플리케이션을 시작 Windows 음성 인식 됩니다도 시작 됩니다. Windows 음성 인식이 경우 합니다 **중지** 상태 이면 다음 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> 항상 null을 반환 합니다.  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        RecognitionResult result;  
  
        // This EmulateRecognize call matches the grammar and returns a  
        // recognition result.  
        result = recognizer.EmulateRecognize("testing testing");  
        OutputResult(result);  
  
        // This EmulateRecognize call does not match the grammar and   
        // returns null.  
        result = recognizer.EmulateRecognize("testing one two three");  
        OutputResult(result);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Output information about a recognition result to the console.  
    private static void OutputResult(RecognitionResult result)  
    {  
      if (result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">인식 작업에 필요한 입력을 포함하는 단어 단위의 배열입니다.</param>
        <param name="compareOptions">에뮬레이트된 인식 작업에 사용할 비교 형식을 설명하는 열거형 값의 비트 조합입니다.</param>
        <summary>동기 음성 인식용 오디오 대신 텍스트를 사용하여 공유 음성 인식기에 특정 단어 입력을 에뮬레이션하고, 인식기가 단어와 로드된 음성 인식 문법 사이의 유니코드 비교를 처리할 방법을 지정합니다.</summary>
        <returns>인식 작업에 대한 인식 결과, 또는 작업이 성공하지 않았거나 Windows 음성 인식이 **중지** 상태인 경우 <see langword="null" /></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 메서드를 만듭니다는 <xref:System.Speech.Recognition.RecognitionResult> 에서 제공 하는 정보를 사용 하 여 개체를 `wordUnits` 매개 변수입니다.  
  
 인식기를 사용 하 여 `compareOptions` 때 적용할 문법 규칙 입력된 구입니다. 인식기 Vista 및 Windows 7을 사용 하 여 제공 되는 경우 대/소문자를 무시 합니다 <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 또는 <xref:System.Globalization.CompareOptions.IgnoreCase> 값이 있음. 인식자 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식자 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions> 열거형입니다.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">인식 작업에 필요한 입력 구입니다.</param>
        <param name="compareOptions">에뮬레이트된 인식 작업에 사용할 비교 형식을 설명하는 열거형 값의 비트 조합입니다.</param>
        <summary>동기 음성 인식용 오디오 대신 텍스트를 사용하여 공유 음성 인식기에 구 입력을 에뮬레이션하고, 인식기가 구와 로드된 음성 인식 문법 사이의 유니코드 비교를 처리할 방법을 지정합니다.</summary>
        <returns>인식 작업에 대한 인식 결과, 또는 작업이 성공하지 않았거나 Windows 음성 인식이 **중지** 상태인 경우 <see langword="null" /></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기를 사용 하 여 `compareOptions` 때 적용할 문법 규칙 입력된 구입니다. 인식기 Vista 및 Windows 7을 사용 하 여 제공 되는 경우 대/소문자를 무시 합니다 <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 또는 <xref:System.Globalization.CompareOptions.IgnoreCase> 값이 있음. 인식자 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식자 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions> 열거형입니다.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognizeAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>비동기 음성 인식을 위한 오디오 대신 텍스트를 사용하여 공유 음성 인식기 입력을 모사합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이러한 메서드는 시스템 오디오 입력을 무시합니다. 이 기능은 테스트 하거나 애플리케이션 또는 문법 디버깅 하는 경우에 유용할 수 있습니다.  
  
 공유 인식기가 발생 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트 것 처럼 인식 작업은 에뮬레이트되지 않습니다. 인식기에는 비동기 인식 작업이 완료 되 면 발생 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> 이벤트입니다. 인식기 새 줄 및 추가 공백을 무시 하 고 리터럴 입력으로 문장 부호를 처리 합니다.  
  
> [!NOTE]
>  Windows 음성 인식이 하는 경우는 **중지** 상태 이면 공유 인식기 입력을 처리 하지 않습니다 하 고 발생 하지 않습니다는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> 및 관련된 이벤트를 있지만 발생은 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> 이벤트입니다.  
  
> [!NOTE]
>  합니다 <xref:System.Speech.Recognition.RecognitionResult> 공유 인식기 에뮬레이트된 입력에 대 한 응답에서으로 생성 된 개체의 값이 `null` 에 대 한 해당 <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> 속성입니다.  
  
 동기 인식 기능을 에뮬레이트하는 데 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> 메서드.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub EmulateRecognizeAsync (inputText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">인식 작업에 필요한 입력입니다.</param>
        <summary>비동기 음성 인식용 오디오 대신 텍스트를 사용하여 공유 음성 인식기에 구 입력을 에뮬레이션합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기 Vista 및 Windows 7을 사용 하 여 제공 되는 대/소문자 무시 및 문자 너비 입력된 구를 문법 규칙을 적용 합니다. 이 유형의 비교에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions> 열거형 값 <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 및 <xref:System.Globalization.CompareOptions.IgnoreWidth>합니다. 또한 인식자 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다.  
  
   
  
## Examples  
 다음 예제는 콘솔 애플리케이션을 음성 인식 문법을 로드 및 비동기 에뮬레이트된 입력, 연결 된 인식 결과 및 음성 인식기에 의해 발생 하는 연결 된 이벤트를 보여 줍니다. Windows 음성 인식을 실행 하지 않는 경우 다음이 애플리케이션을 시작 Windows 음성 인식 됩니다도 시작 됩니다. Windows 음성 인식이 경우 합니다 **중지** 상태 이면 다음 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 항상 null을 반환 합니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">인식 작업에 필요한 입력을 포함하는 단어 단위의 배열입니다.</param>
        <param name="compareOptions">에뮬레이트된 인식 작업에 사용할 비교 형식을 설명하는 열거형 값의 비트 조합입니다.</param>
        <summary>비동기 음성 인식용 오디오 대신 텍스트를 사용하여 공유 음성 인식기에 특정 단어 입력을 에뮬레이션하고, 인식기가 단어와 로드된 음성 인식 문법 사이의 유니코드 비교를 처리할 방법을 지정합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 메서드를 만듭니다는 <xref:System.Speech.Recognition.RecognitionResult> 에서 제공 하는 정보를 사용 하 여 개체를 `wordUnits` 매개 변수입니다.  
  
 인식기를 사용 하 여 `compareOptions` 때 적용할 문법 규칙 입력된 구입니다. 인식기 Vista 및 Windows 7을 사용 하 여 제공 되는 경우 대/소문자를 무시 합니다 <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 또는 <xref:System.Globalization.CompareOptions.IgnoreCase> 값이 있음. 인식자 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식자 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions> 열거형입니다.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">인식 작업에 필요한 입력 구입니다.</param>
        <param name="compareOptions">에뮬레이트된 인식 작업에 사용할 비교 형식을 설명하는 열거형 값의 비트 조합입니다.</param>
        <summary>비동기 음성 인식용 오디오 대신 텍스트를 사용하여 공유 음성 인식기에 구 입력을 에뮬레이션하고, 인식기가 구와 로드된 음성 인식 문법 사이의 유니코드 비교를 처리할 방법을 지정합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기를 사용 하 여 `compareOptions` 때 적용할 문법 규칙 입력된 구입니다. 인식기 Vista 및 Windows 7을 사용 하 여 제공 되는 경우 대/소문자를 무시 합니다 <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 또는 <xref:System.Globalization.CompareOptions.IgnoreCase> 값이 있음. 인식자 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다. 또한 인식자 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다. 문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 <xref:System.Globalization.CompareOptions> 열거형입니다.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event EmulateRecognizeCompleted As EventHandler(Of EmulateRecognizeCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::EmulateRecognizeCompletedEventArgs ^&gt; ^ EmulateRecognizeCompleted;" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeCompleted : EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " Usage="member this.EmulateRecognizeCompleted : System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>공유 인식기 에뮬레이트된 입력에 대 한 비동기 인식 작업을 종료 할 때 발생 합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 각 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 메서드는 비동기 인식 작업을 시작 합니다. 인식기가 발생 합니다 `EmulateRecognizeCompleted` 비동기 작업을 완료 하는 경우에 이벤트입니다.  
  
 비동기 인식 작업을 발생 시킬 수는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>를 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, 및 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트입니다. <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> 이벤트는 마지막 이러한 이벤트 인식기를 지정된 된 작업에 대 한 발생 시킵니다.  
  
 에 대 한 대리자를 만들 때는 `EmulateRecognizeCompleted` 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제는 콘솔 애플리케이션을 음성 인식 문법을 로드 및 비동기 에뮬레이트된 입력, 연결 된 인식 결과 및 음성 인식기에 의해 발생 하는 연결 된 이벤트를 보여 줍니다. Windows 음성 인식을 실행 하지 않는 경우 다음이 애플리케이션을 시작 Windows 음성 인식 됩니다도 시작 됩니다. Windows 음성 인식이 경우 합니다 **중지** 모드에서는 다음 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 항상 null을 반환 합니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=   
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar  
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="Enabled">
      <MemberSignature Language="C#" Value="public bool Enabled { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool Enabled" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberSignature Language="VB.NET" Value="Public Property Enabled As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool Enabled { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.Enabled : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>이 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 개체가 음성을 처리할 준비가 되었는지 여부를 나타내는 값을 가져오거나 설정합니다.</summary>
        <value>이 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 개체가 음성 인식을 수행하고 있으면 <see langword="true" />이고, 그렇지 않으면 <see langword="false" />입니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 속성 변경의 다른 인스턴스에 영향을 주지 않습니다는 <xref:System.Speech.Recognition.SpeechRecognizer> 클래스입니다.  
  
 기본적으로 값을 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> 속성은 `true` 는 새로 인스턴스화된 인스턴스의 <xref:System.Speech.Recognition.SpeechRecognizer>합니다. 인식기를 사용 하지 않도록 설정 하는 동안 인식기의 음성 인식 문법 하나도 인식 작업에 사용할 수 있습니다. 인식기를 설정 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> 속성이 인식기에 영향을 주지 <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> 속성입니다.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      </Docs>
    </Member>
    <Member MemberName="Grammars">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt; Grammars { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.Grammar&gt; Grammars" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammars As ReadOnlyCollection(Of Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ Grammars { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammars : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;" Usage="System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>이 <see cref="T:System.Speech.Recognition.Grammar" /> 인스턴스에 로드된 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 개체의 컬렉션을 가져옵니다.</summary>
        <value>애플리케이션이 공유된 인식기의 현재 인스턴스에 로드한 <see cref="T:System.Speech.Recognition.Grammar" /> 개체의 컬렉션입니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 속성 모든 음성 인식 문법이 로드 다른 애플리케이션에서 반환 하지 않습니다.  
  
   
  
## Examples  
 다음 예제에서는 공유 음성 인식기에 로드 된 각 음성 인식 문법에 대 한 콘솔에 정보를 출력 합니다.  
  
```csharp  
  
using System;  
using System.Collections.Generic;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Grammar sampleGrammar = new Grammar(new GrammarBuilder("sample phrase"));  
        sampleGrammar.Name = "Sample Grammar";  
        recognizer.LoadGrammar(sampleGrammar);  
  
        OutputGrammarList(recognizer);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void OutputGrammarList(SpeechRecognizer recognizer)  
    {  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      if (grammars.Count > 0)  
      {  
        Console.WriteLine("Loaded grammars:");  
        foreach (Grammar g in grammars)  
        {  
          Console.WriteLine("  Grammar: {0}",  
            (g.Name != null) ? g.Name : "<no name>");  
        }  
      }  
      else  
      {  
        Console.WriteLine("No grammars loaded.");  
      }  
    }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammar">
      <MemberSignature Language="C#" Value="public void LoadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">로드할 음성 인식 문법입니다.</param>
        <summary>음성 인식 문법을 로드합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 공유 인식기가 음성 인식 문법을 비동기적으로 로드 되, 모든 인식기에 로드 하지 못했습니다이 이미 로드 하는 경우 예외를 throw 합니다. 인식기를 실행 하는 경우 애플리케이션 사용 해야 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 로드, 언로드을 사용 하도록 설정 또는 문법을 사용 하지 않도록 설정 하기 전에 음성 인식 엔진을 일시 중지 합니다.  
  
 음성 인식 문법을 비동기적으로 로드 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> 메서드.  
  
   
  
## Examples  
 다음 예제는 콘솔 애플리케이션을 음성 인식 문법을 로드 및 비동기 에뮬레이트된 입력, 연결 된 인식 결과 및 음성 인식기에 의해 발생 하는 연결 된 이벤트를 보여 줍니다. Windows 음성 인식을 실행 하지 않는 경우 다음이 애플리케이션을 시작 Windows 음성 인식 됩니다도 시작 됩니다. Windows 음성 인식이 경우 합니다 **중지** 상태 이면 다음 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 항상 null을 반환 합니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }   
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarAsync">
      <MemberSignature Language="C#" Value="public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammarAsync(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammarAsync(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarAsync : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammarAsync grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">로드할 음성 인식 문법입니다.</param>
        <summary>음성 인식 문법을 비동기적으로 로드합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기에는이 비동기 작업이 완료 되 면 발생 한 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> 이벤트입니다. 인식기에 음성 인식 문법 이미 로드 또는 비동기적으로 로드 되 고, 모든 인식기에 로드 하지 못했습니다 경우 예외가 throw 됩니다. 인식기를 실행 하는 경우 애플리케이션 사용 해야 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 로드, 언로드을 사용 하도록 설정 또는 문법을 사용 하지 않도록 설정 하기 전에 음성 인식 엔진을 일시 중지 합니다.  
  
 음성 인식 문법의 동기적으로 로드 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A> 메서드.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event LoadGrammarCompleted As EventHandler(Of LoadGrammarCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::LoadGrammarCompletedEventArgs ^&gt; ^ LoadGrammarCompleted;" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarCompleted : EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " Usage="member this.LoadGrammarCompleted : System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식기는 음성 인식의 문법의 비동기 로딩을 완료할 때 발생 합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> 메서드는 비동기 작업을 시작 합니다. 인식기가 발생 합니다 `LoadGrammarCompleted` 이벤트는 작업을 완료 하는 경우. 가져오려는 합니다 <xref:System.Speech.Recognition.Grammar> 인식기에 로드 된 개체를 사용 하 여는 <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> 속성은 연결 된 <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>합니다. 현재 가져오려는 <xref:System.Speech.Recognition.Grammar> 인식기를 사용 하는 인식기를 로드 하는 개체 <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> 속성입니다.  
  
 대리자를 만드는 경우는 `LoadGrammarCompleted` 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제에서는 공유 음성 인식기를 만들고 두 가지 유형의 무료 받아쓰기 허용 및 특정 단어를 인식 하는 것에 대 한 문법을 만듭니다. 이 예제에서는 인식기에 만든된 모든 문법을 비동기적으로 로드합니다. 인식기에 대 한 처리기 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> 고 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트 인식 및 텍스트 인식 결과를 각각 수행 하는 문법의 이름을 콘솔에 기록 합니다.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Add a handler for the StateChanged event.  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Create "yesno" grammar.  
        Choices yesChoices = new Choices(new string[] { "yes", "yup", "yeah}" });  
        SemanticResultValue yesValue =  
            new SemanticResultValue(yesChoices, (bool)true);  
        Choices noChoices = new Choices(new string[] { "no", "nope", "neah" });  
        SemanticResultValue noValue =  
            new SemanticResultValue(noChoices, (bool)false);  
        SemanticResultKey yesNoKey =  
            new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
        Grammar yesnoGrammar = new Grammar(yesNoKey);  
        yesnoGrammar.Name = "yesNo";  
  
        // Create "done" grammar.  
        Grammar doneGrammar =  
          new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
        doneGrammar.Name = "Done";  
  
        // Create dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation";  
  
        // Load grammars to the recognizer.  
        recognizer.LoadGrammarAsync(yesnoGrammar);  
        recognizer.LoadGrammarAsync(doneGrammar);  
        recognizer.LoadGrammarAsync(dictation);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  
    // Put the shared speech recognizer into "listening" mode.   
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.LoadGrammarCompletedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="MaxAlternates">
      <MemberSignature Language="C#" Value="public int MaxAlternates { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 MaxAlternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxAlternates As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int MaxAlternates { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.MaxAlternates : int with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>각 인식 작업을 위해 공유 음성 인식기에서 반환하는 대체 인식 결과의 최대 개수를 가져오거나 설정합니다.</summary>
        <value>각 인식 작업을 위해 음성 인식기에서 반환하는 대체 결과의 최대 개수입니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> 의 속성을 <xref:System.Speech.Recognition.RecognitionResult> 클래스의 컬렉션을 포함 <xref:System.Speech.Recognition.RecognizedPhrase> 입력의 다른 후보 해석을 나타내는 개체.  
  
 에 대 한 기본값 <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> 은 10입니다.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="PauseRecognizerOnRecognition">
      <MemberSignature Language="C#" Value="public bool PauseRecognizerOnRecognition { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool PauseRecognizerOnRecognition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberSignature Language="VB.NET" Value="Public Property PauseRecognizerOnRecognition As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool PauseRecognizerOnRecognition { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.PauseRecognizerOnRecognition : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>애플리케이션에서 <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> 이벤트를 처리하는 동안 공유 인식기가 인식 작업을 일시 중지하는지를 나타내는 값을 가져오거나 설정합니다.</summary>
        <value>공유 인식기가 응용 프로그램이 <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> 이벤트를 처리하는 동안 입력을 처리하기 위해 기다리는 경우 <see langword="true" />이고, 그렇지 않은 경우  <see langword="false" />입니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 속성을 설정 `true`경우에 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 애플리케이션이 음성 인식 서비스의 상태를 변경 하거나 음성 인식 서비스 전에 로드 되거나 설정 된 음성 인식 문법 변경 해야 하는 이벤트 처리기 프로세스를 더 입력 합니다.  
  
> [!NOTE]
>  설정 된 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 속성을 `true` 하면 각 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> Windows 음성 인식 서비스를 차단 하도록 모든 애플리케이션에서 이벤트 처리기입니다.  
  
 공유 인식기가 변경 내용을 애플리케이션 상태와 동기화를 사용 하 여를 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 메서드.  
  
 때 <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> 은 `true`를 실행 하는 동안는 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 처리기 음성 인식 서비스 일시 중지 하 고 도착 하는 대로 새 오디오 입력을 버퍼링 합니다. 한 번의 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 음성 인식 서비스 다시 시작 인식 및 입력된 버퍼에서 정보를 처리 하기 시작에 이벤트 처리기가 종료 됩니다.  
  
 를 사용 하도록 설정 하거나 음성 인식 서비스를 사용 하지 않도록 설정 된 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> 속성입니다.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerAudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan RecognizerAudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan RecognizerAudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerAudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan RecognizerAudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerAudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>처리하고 있는 오디오 입력 인식기의 현재 위치를 가져옵니다.</summary>
        <value>처리 중인 오디오 입력 인식기의 위치입니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `RecognizerAudioPosition` 오디오 입력 처리 인식기의 위치를 참조 하는 속성입니다. 반면,는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 속성이 생성 된 해당 오디오 스트림에서 입력된 디바이스의 위치를 참조 합니다. 이러한 위치는 다를 수 있습니다. 예를 들어 인식기에서 받은 입력 하지 있는 it에 아직 경우 인식 결과 다음 값을 생성 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 속성의 값 보다 작으면는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 속성.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerInfo">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizerInfo RecognizerInfo" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerInfo As RecognizerInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerInfo ^ RecognizerInfo { System::Speech::Recognition::RecognizerInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerInfo : System.Speech.Recognition.RecognizerInfo" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>공유 음성 인식기에 대한 정보를 가져옵니다.</summary>
        <value>공유 음성 인식기에 대한 정보.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 속성에서 사용 하 여 Windows 음성 인식 하 여 음성 인식기에 대 한 정보를 반환합니다.  
  
   
  
## Examples  
 다음 예제에서는 콘솔에 공유 인식기에 대 한 정보를 보냅니다.  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Console.WriteLine("Recognizer information for the shared recognizer:");  
        Console.WriteLine("  Name: {0}", recognizer.RecognizerInfo.Name);  
        Console.WriteLine("  Culture: {0}", recognizer.RecognizerInfo.Culture.ToString());  
        Console.WriteLine("  Description: {0}", recognizer.RecognizerInfo.Description);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerInfo" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerUpdateReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      <MemberSignature Language="VB.NET" Value="Public Event RecognizerUpdateReached As EventHandler(Of RecognizerUpdateReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::RecognizerUpdateReachedEventArgs ^&gt; ^ RecognizerUpdateReached;" />
      <MemberSignature Language="F#" Value="member this.RecognizerUpdateReached : EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " Usage="member this.RecognizerUpdateReached : System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식 및 기타 작업을 동기화 하는 인식기를 놓을 때 발생 합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 애플리케이션을 사용 해야 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 를 실행 중인 인스턴스 일시 중지 <xref:System.Speech.Recognition.SpeechRecognizer> 수정 하기 전에 해당 <xref:System.Speech.Recognition.Grammar> 개체입니다. 예를 들어 하는 동안 합니다 <xref:System.Speech.Recognition.SpeechRecognizer> 는 일시 중지 된 로드, 언로드를 활성화 및 비활성화할 수 있습니다 <xref:System.Speech.Recognition.Grammar> 개체입니다. <xref:System.Speech.Recognition.SpeechRecognizer> 수정을 적용 하기 위해 준비 되 면이 이벤트가 발생 합니다.  
  
 대리자를 만드는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제에서는 콘솔 애플리케이션을 로드 하 고 언로드합니다 <xref:System.Speech.Recognition.Grammar> 개체입니다. 애플리케이션을 사용 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 음성 인식 엔진 업데이트를 받을 수 있도록 일시 중지를 요청 하는 방법입니다. 애플리케이션을 로드 하거나 언로드합니다를 <xref:System.Speech.Recognition.Grammar> 개체입니다.  
  
 각 업데이트에 대 한 처리기에서 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이름 및 현재 로드 된 상태의 이벤트 기록 <xref:System.Speech.Recognition.Grammar> 콘솔에는 개체입니다. 문법, 로드 및 언로드될 때 팜 동물의 이름은 팜에 동물 이름과 과일을 차례로 과일의 이름만 먼저 애플리케이션에 인식 합니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
      </Docs>
    </Member>
    <MemberGroup MemberName="RequestRecognizerUpdate">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>공유된 인식기가 그 상태를 멈추고 업데이트할 것을 요청합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 공유 인식기에 대 한 변경 내용을 동기화 하려면이 메서드를 사용 합니다. 로드 하거나 언로드하면 스피치 인식 그래 머 인식기 처리 하는 동안 입력을 하는 경우 예를 들어이 메서드를 사용 하며 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 인식기의 상태를 사용 하 여 애플리케이션 동작을 동기화 하는 이벤트입니다.  
  
 이 메서드를 호출 하는 경우 인식기 일시 중지 또는 비동기 작업을 완료 하 고 생성 된 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트입니다. <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트 처리기 상태 인식 작업 사이 인식기를 수정할 수 있습니다.  
  
 이 메서드가 호출 될 때를 나타냅니다.  
  
-   인식기를 즉시 생성 인식기 입력을 처리 하지 않은, 경우를 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트입니다.  
  
-   인식기 대기 또는 배경 소음으로 구성 된 입력을 처리 하 고, 있으면 인식기 인식 작업을 일시 중지 하 고 생성 된 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트입니다.  
  
-   인식기 인식 작업을 완료 한 다음 생성 인식기 입력 하지 않았기 대기 또는 배경 소음을 처리 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트입니다.  
  
 인식기 처리 하는 동안는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트:  
  
-   인식기에는 입력 및의 값을 처리 하지 않습니다는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 속성 동일 하 게 유지 합니다.  
  
-   인식기 입력을 수집 하 고 값을 계속 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 속성을 변경할 수 있습니다.  
  
 애플리케이션 처리 하는 동안 공유 인식기가 인식 작업을 일시 중지 여부를 변경 하는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트를 사용 하 여는 <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> 속성.  
  
   
  
## Examples  
 다음 예제에서는 콘솔 애플리케이션을 로드 하 고 언로드합니다 <xref:System.Speech.Recognition.Grammar> 개체입니다. 애플리케이션을 사용 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 음성 인식 엔진 업데이트를 받을 수 있도록 일시 중지를 요청 하는 방법입니다. 애플리케이션을 로드 하거나 언로드합니다를 <xref:System.Speech.Recognition.Grammar> 개체입니다.  
  
 각 업데이트에 대 한 처리기에서 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이름 및 현재 로드 된 상태의 이벤트 기록 <xref:System.Speech.Recognition.Grammar> 콘솔에는 개체입니다. 문법, 로드 및 언로드될 때 팜 동물의 이름은 팜에 동물 이름과 과일을 차례로 과일의 이름만 먼저 애플리케이션에 인식 합니다.  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
  
      // Check to see if recognizer is loaded, wait if it is not loaded.  
      if (recognizer.State != RecognizerState.Listening)  
      {  
        Thread.Sleep(5000);  
  
        // Put recognizer in listening state.  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      // At the update, get the names and enabled status of the currently loaded grammars.  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      </Docs>
    </MemberGroup>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate();" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : unit -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>공유된 인식기가 그 상태를 멈추고 업데이트할 것을 요청합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트를 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> 의 속성을 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> 는 `null`.  
  
 사용자 토큰을 제공 하려면 사용 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 또는 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 메서드. 오디오 위치 오프셋을 지정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 메서드.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate userToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
      </Parameters>
      <Docs>
        <param name="userToken">작업에 대한 정보가 포함된 사용자 정의 정보입니다.</param>
        <summary>공유 인식기가 일시 중지되어 상태를 업데이트하고 관련된 이벤트에 대한 사용자 토큰을 제공하도록 요청합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트를 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> 의 속성을 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> 의 값을 포함는 `userToken` 매개 변수.  
  
 오디오 위치 오프셋을 지정 하려면 사용 된 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 메서드.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken, valuetype System.TimeSpan audioPositionAheadToRaiseUpdate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object, audioPositionAheadToRaiseUpdate As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj * TimeSpan -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate (userToken, audioPositionAheadToRaiseUpdate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
        <Parameter Name="audioPositionAheadToRaiseUpdate" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="userToken">작업에 대한 정보가 포함된 사용자 정의 정보입니다.</param>
        <param name="audioPositionAheadToRaiseUpdate">요청을 지연하는 현재 <see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />의 오프셋입니다.</param>
        <summary>공유 인식기가 일시 중지되어 상태를 업데이트하고 관련된 이벤트에 대한 오프셋과 사용자 토큰을 제공하도록 요청합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기가 인식기까지 인식기 업데이트 요청을 시작 하지 않습니다 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 현재 equals <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 값을 더한 값을 `audioPositionAheadToRaiseUpdate` 매개 변수입니다.  
  
 인식기 생성 하는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 이벤트를 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> 의 속성을 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> 의 값을 포함는 `userToken` 매개 변수.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechDetected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechDetected As EventHandler(Of SpeechDetectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechDetectedEventArgs ^&gt; ^ SpeechDetected;" />
      <MemberSignature Language="F#" Value="member this.SpeechDetected : EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " Usage="member this.SpeechDetected : System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식기가 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 공유 인식기가 입력에 대 한 응답에서이 이벤트를 발생 시킬 수 있습니다. 합니다 <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> 속성은 연결 된 <xref:System.Speech.Recognition.SpeechDetectedEventArgs> 개체를 인식기에서 음성을 검색 하는 경우 입력 스트림의 위치를 나타냅니다. 자세한 내용은 참조는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 하 고 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 속성 및 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> 및 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 메서드.  
  
 대리자를 만드는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제는 항공편에 대 한 원본 및 대상 도시를 선택 하는 것에 대 한 콘솔 애플리케이션의 일부입니다. 애플리케이션 "시카고에 마이애미에서 fly 하려고 합니다."와 같은 구를 인식합니다  예제에서는 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> 보고서에는 이벤트는 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 각 시간 음성이 감지 되는 합니다.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        Choices cities = new Choices(new string[] {   
          "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I would like to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Create a Grammar object and load it to the recognizer.  
        Grammar g = new Grammar(gb);  
        g.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(g);  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechDetected +=   
          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechDetected event.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine("Speech detected at AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechHypothesized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechHypothesized As EventHandler(Of SpeechHypothesizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechHypothesizedEventArgs ^&gt; ^ SpeechHypothesized;" />
      <MemberSignature Language="F#" Value="member this.SpeechHypothesized : EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " Usage="member this.SpeechHypothesized : System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식기가 단어가 문법적으로 여러 구의 구성 요소가 될 수 있음을 인식했을 때 발생합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 공유 인식기 입력이 모호한 경우이 이벤트를 발생 시킬 수 있습니다. 음성 인식 문법을 인식의에 지에 대 한 예를 들어, "새 게임 하세요" 또는 "새 게임"을 "새 하세요 게임" 명확한 입력 이며 "new game" 모호한 입력 합니다.  
  
 대리자를 만드는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제에서는 "재즈 범주의 artist 목록 표시"와 같은 구를 인식합니다. 이 예제에서는 사용을 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> 인식 되는 대로 불완전 한 구 조각을 콘솔에서 표시할 이벤트입니다.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display the list of");  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the");  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category.");  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechHypothesized +=   
          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine("Speech hypothesized: " + e.Result.Text);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionRejected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognitionRejected As EventHandler(Of SpeechRecognitionRejectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognitionRejectedEventArgs ^&gt; ^ SpeechRecognitionRejected;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognitionRejected : EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " Usage="member this.SpeechRecognitionRejected : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식기가 로드된 음성 인식 문법 중 어느것과도 일치하지 않는 입력을 받을 때 발생합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 공유 인식기 입력 일치 하지 않음을 충분 한 신뢰를 사용 하 여 로드 된 음성 인식 문법 중 하나를 결정 하는 경우이 이벤트를 발생 시킵니다. <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> 의 속성을 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> 거부 포함 <xref:System.Speech.Recognition.RecognitionResult> 개체입니다.  
  
 관리 하는 공유 인식기에 대 한 신뢰도 임계값 <xref:System.Speech.Recognition.SpeechRecognizer>, 사용자 프로필과 연결 되며 Windows 레지스트리에 저장 합니다. 애플리케이션 공유 된 인식기의 속성에 대 한 레지스트리 변경을 작성 해야 합니다.  
  
 대리자를 만드는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제에서는 "재즈 범주의 artist 목록을 표시" 또는 "앨범 절대적인 표시"와 같은 구를 인식 합니다. 이 예제에서는 사용에 대 한 처리기를 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> 음성 입력 성공적인 인식을 생성 하는 데 충분 한 신뢰를 사용 하 여 문법의 내용에 일치 시킬 수 없는 경우 콘솔에서 알림을 표시 하는 이벤트입니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display");  
        mediaMenu.Append("the list of", 0, 1);  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the", 0, 1);  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category", 0, 1);  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechRecognitionRejected +=   
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("Speech input was rejected.");  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognized As EventHandler(Of SpeechRecognizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognizedEventArgs ^&gt; ^ SpeechRecognized;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognized : EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " Usage="member this.SpeechRecognized : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>인식기의 음성 인식의 문법 중 하 나와 일치 하는 입력을 받을 때 발생 합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기가 발생 합니다 `SpeechRecognized` 입력 로드 하 고 사용할 음성 인식 문법 중 하 나와 일치 하는 하는 데 충분 한 신뢰를 사용 하 여 결정 하는 경우에 이벤트입니다. 합니다 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> 의 속성을 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> 포함 허용 되 <xref:System.Speech.Recognition.RecognitionResult> 개체입니다.  
  
 관리 하는 공유 인식기에 대 한 신뢰도 임계값 <xref:System.Speech.Recognition.SpeechRecognizer>, 사용자 프로필과 연결 되며 Windows 레지스트리에 저장 합니다. 애플리케이션 공유 된 인식기의 속성에 대 한 레지스트리 변경을 작성 해야 합니다.  
  
 인식기 문법에 일치 하는 입력을 받을 때 합니다 <xref:System.Speech.Recognition.Grammar> 개체를 발생 시킬 수는 <xref:System.Speech.Recognition.Grammar.SpeechRecognized> 이벤트입니다. 합니다 <xref:System.Speech.Recognition.Grammar> 개체의 <xref:System.Speech.Recognition.Grammar.SpeechRecognized> 이벤트는 음성 인식기의 이전 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트입니다.  
  
 대리자를 만드는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제는 콘솔 애플리케이션을 음성 인식 문법을 로드 하 고 음성 인식기에 의해 발생 하는 연결 된 이벤트, 연결 된 인식 결과, 및 공유 인식기에 음성 입력을 보여 줍니다. Windows 음성 인식을 실행 하지 않는 경우 다음이 애플리케이션을 시작 Windows 음성 인식 됩니다도 시작 됩니다.  
  
 "시카고에서 마이애미 갈"을 트리거할 같은 입력 음성는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트입니다. "Fly me Houston에서 시카고로" 라는 문구를 말하기 트리거되지는 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 이벤트입니다.  
  
 이 예제에서는 사용에 대 한 처리기를 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> 성공적으로 표시할 이벤트 구 및 콘솔에 포함 된 의미 체계를 인식 합니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      </Docs>
    </Member>
    <Member MemberName="State">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerState State { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.RecognizerState State" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property State As RecognizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerState State { System::Speech::Recognition::RecognizerState get(); };" />
      <MemberSignature Language="F#" Value="member this.State : System.Speech.Recognition.RecognizerState" Usage="System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 개체의 상태를 가져옵니다.</summary>
        <value><see langword="SpeechRecognizer" /> 개체의 상태입니다.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 이 읽기 전용 속성에 Windows 공유 인식기 인지 여부를 나타냅니다 합니다 `Stopped` 또는 `Listening` 상태입니다. 자세한 내용은 <xref:System.Speech.Recognition.RecognizerState> 열거형을 참조하세요.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="StateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Event StateChanged As EventHandler(Of StateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::StateChangedEventArgs ^&gt; ^ StateChanged;" />
      <MemberSignature Language="F#" Value="member this.StateChanged : EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " Usage="member this.StateChanged : System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Windows 바탕 화면 음성 기술을 인식 엔진의 실행 상태가 변경 될 때 발생 합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 공유 인식기가 Windows 음성 인식의 상태를 변경 하는 경우이 이벤트를 발생 시킵니다. 합니다 <xref:System.Speech.Recognition.RecognizerState.Listening> 또는 <xref:System.Speech.Recognition.RecognizerState.Stopped> 상태입니다.  
  
 공유 인식기가 상태 이벤트의 타임을 사용 합니다 <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> 속성은 연결 된 <xref:System.Speech.Recognition.StateChangedEventArgs>합니다. 공유 된 인식기의 현재 상태를 가져오려면 인식기를 사용 하 여 <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> 속성입니다.  
  
 대리자를 만드는 경우는 <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> 이벤트에 이벤트를 처리 하는 메서드를 식별 합니다. 이벤트를 이벤트 처리기와 연결하려면 대리자의 인스턴스를 해당 이벤트에 추가합니다. 대리자를 제거하지 않는 경우 이벤트가 발생할 때마다 이벤트 처리기가 호출됩니다. 이벤트 처리기 대리자에 대 한 자세한 내용은 참조 하세요. [이벤트 및 대리자](https://go.microsoft.com/fwlink/?LinkId=162418)합니다.  
  
   
  
## Examples  
 다음 예제에서는 공유 음성 인식기를 만들고 두 가지 유형의 무료 받아쓰기 허용 및 특정 단어를 인식 하는 것에 대 한 문법을 만듭니다. 이 예제에서는 인식기에 만든된 모든 문법을 비동기적으로 로드합니다.  에 대 한 처리기를 <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> 이벤트를 사용 하는 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> Windows 인식 "수신 대기" 모드로 전환 하는 방법입니다.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the SpeechRecognized event.  
      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
      // Add a handler for the StateChanged event.  
      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Create "yesno" grammar.  
      Choices yesChoices = new Choices(new string[] { "yes", "yup", "yah}" });  
      SemanticResultValue yesValue =  
          new SemanticResultValue(yesChoices, (bool)true);  
      Choices noChoices = new Choices(new string[] { "no", "nope", "nah" });  
      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  
      SemanticResultKey yesNoKey =  
          new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
      Grammar yesnoGrammar = new Grammar(yesNoKey);  
      yesnoGrammar.Name = "yesNo";  
  
      // Create "done" grammar.  
      Grammar doneGrammar =  
        new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
      doneGrammar.Name = "Done";  
  
      // Create dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load grammars to the recognizer.  
      recognizer.LoadGrammarAsync(yesnoGrammar);  
      recognizer.LoadGrammarAsync(doneGrammar);  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
     if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
     Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
     string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
      }  
  
      // Add exception handling code here.  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="UnloadAllGrammars">
      <MemberSignature Language="C#" Value="public void UnloadAllGrammars ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadAllGrammars() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      <MemberSignature Language="VB.NET" Value="Public Sub UnloadAllGrammars ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadAllGrammars();" />
      <MemberSignature Language="F#" Value="member this.UnloadAllGrammars : unit -&gt; unit" Usage="speechRecognizer.UnloadAllGrammars " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>모든 음성 인식 문법을 공유 인식기에서 언로드합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기가 현재 문법을 비동기적으로 로드 하는 경우이 메서드는 모든 인식기의 문법 언로드합니다 전에 문법을 로드 될 때까지 대기 합니다.  
  
 특정 문법을 언로드 작업을 사용 하 여를 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> 메서드.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="UnloadGrammar">
      <MemberSignature Language="C#" Value="public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.UnloadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.UnloadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">언로드할 문법입니다.</param>
        <summary>지정된 음성 인식 문법을 공유 인식기에서 언로드합니다.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 인식기를 실행 하는 경우 애플리케이션 사용 해야 합니다 <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 로드, 언로드을 사용 하도록 설정 또는 문법을 사용 하지 않도록 설정 하기 전에 음성 인식 엔진을 일시 중지 합니다. 모든 문법 언로드 작업을 사용 하 여를 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> 메서드.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      </Docs>
    </Member>
  </Members>
</Type>